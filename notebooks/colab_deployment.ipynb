{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Semantic Segmentation - Google Colab Deployment\n",
    "\n",
    "This notebook deploys the real-time segmentation server on Google Colab with GPU acceleration.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable GPU**: Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `GPU`\n",
    "2. **Get ngrok token**: Sign up at https://ngrok.com and get your auth token\n",
    "3. **Run cells in order**: Execute each cell sequentially\n",
    "4. **Access app**: Use the ngrok URL provided in the output\n",
    "\n",
    "## Note\n",
    "- Colab sessions timeout after 12 hours or 90 minutes idle\n",
    "- GPU allocation is not guaranteed (T4/P100/V100 depending on availability)\n",
    "- Save models to Google Drive for persistence across sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository (replace with your repo URL)\n",
    "!git clone https://github.com/yourusername/RealTimeSeg.git\n",
    "%cd RealTimeSeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA support\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install other requirements\n",
    "!pip install -r backend/requirements.txt\n",
    "\n",
    "# Install ngrok for tunneling\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download and Cache Models (Optional)\n",
    "\n",
    "Pre-download models to speed up startup. Models will be cached for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models.segmentation as models\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "print(\"Downloading models...\")\n",
    "\n",
    "# Download DeepLabV3 models\n",
    "print(\"1/3 Downloading DeepLabV3-MobileNetV3...\")\n",
    "_ = models.deeplabv3_mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "print(\"2/3 Downloading DeepLabV3-ResNet50...\")\n",
    "_ = models.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "print(\"3/3 Downloading SegFormer-B3...\")\n",
    "_ = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    \"nvidia/segformer-b3-finetuned-ade-512-512\"\n",
    ")\n",
    "\n",
    "print(\"‚úì All models downloaded and cached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup ngrok Tunnel\n",
    "\n",
    "**Important**: Replace `YOUR_NGROK_TOKEN` with your actual ngrok auth token from https://ngrok.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok, conf\n",
    "import os\n",
    "\n",
    "# Set your ngrok auth token here\n",
    "NGROK_TOKEN = \"YOUR_NGROK_TOKEN\"  # Replace with your token\n",
    "\n",
    "# Configure ngrok\n",
    "conf.get_default().auth_token = NGROK_TOKEN\n",
    "\n",
    "# Create tunnel\n",
    "public_url = ngrok.connect(8000)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üåê PUBLIC URL: {public_url}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "print(f\"Open this URL in your browser to access the app!\")\n",
    "print(f\"\\nNote: This URL is valid for this Colab session only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Start Server\n",
    "\n",
    "This will start the FastAPI server. The cell will keep running - don't stop it!\n",
    "\n",
    "**Access your app**: Open the ngrok URL from the previous cell in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('backend')\n",
    "\n",
    "# Set environment to use GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Start the server\n",
    "!cd backend && python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Keep Session Alive (Optional)\n",
    "\n",
    "Run this in a separate cell to prevent Colab from disconnecting due to inactivity.\n",
    "\n",
    "**Note**: This is optional and should be used responsibly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Keep-alive started. Press 'Stop' button to end.\")\n",
    "print(\"This will print a message every 60 seconds.\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"[{current_time}] Session active...\")\n",
    "        time.sleep(60)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nKeep-alive stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### GPU Not Available\n",
    "- Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `GPU`\n",
    "- Restart runtime and run cells again\n",
    "\n",
    "### ngrok Connection Failed\n",
    "- Check that your ngrok token is correct\n",
    "- Free tier has connection limits (40 connections/min)\n",
    "- Try regenerating the tunnel (run ngrok cell again)\n",
    "\n",
    "### Server Won't Start\n",
    "- Check that all dependencies installed successfully\n",
    "- Make sure you're in the correct directory\n",
    "- Review error messages in cell output\n",
    "\n",
    "### Models Loading Slowly\n",
    "- First run downloads models (~2-3 GB)\n",
    "- Subsequent runs use cached models (faster)\n",
    "- Consider mounting Google Drive for persistent cache\n",
    "\n",
    "## Performance Tips\n",
    "\n",
    "1. **Start with Balanced Mode**: Good trade-off between speed and accuracy\n",
    "2. **Monitor GPU Memory**: Check `nvidia-smi` if experiencing issues\n",
    "3. **Reduce Resolution**: If laggy, lower webcam resolution in browser\n",
    "4. **Close Other Tabs**: Browser resources affect webcam capture performance"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
